# Ultralytics YOLO ğŸš€, AGPL-3.0 license

from ultralytics.engine.predictor import BasePredictor
from ultralytics.engine.results import Results
from ultralytics.utils import ops

import shutil,torch

class DetectionPredictor(BasePredictor):
    """
    A class extending the BasePredictor class for prediction based on a detection model.

    Example:
        ```python
        from ultralytics.utils import ASSETS
        from ultralytics.models.yolo.detect import DetectionPredictor

        args = dict(model='yolov8n.pt', source=ASSETS)
        predictor = DetectionPredictor(overrides=args)
        predictor.predict_cli()
        ```
    """

    def postprocess(self, preds, img, orig_imgs):
        """Post-processes predictions and returns a list of Results objects."""
        preds = ops.non_max_suppression(preds,
                                        self.args.conf,
                                        self.args.iou,
                                        agnostic=self.args.agnostic_nms,
                                        max_det=self.args.max_det,
                                        classes=self.args.classes)

        if not isinstance(orig_imgs, list):  # input images are a torch.Tensor, not a list
            orig_imgs = ops.convert_torch2numpy_batch(orig_imgs)

        results = []
        for i, pred in enumerate(preds):
            orig_img = orig_imgs[i]
            pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], orig_img.shape)
            img_path = self.batch[0][i]
            results.append(Results(orig_img, path=img_path, names=self.model.names, boxes=pred))  
            # #tag:ä¿®æ”¹ æ·»åŠ ä¸‹é¢å››è¡Œä»£ç 
            # if results[0].boxes.shape[0] == 0 :
            #     shutil.move(img_path,dst='/media/xnwu/2AC0DAF3C0DAC3EB/Datasets/DVR/data/20230614/20230614_for_obj_det_noObj' )
            if torch.any(results[0].boxes.cls==0.) :  #  åˆ¤æ–­ä¸€ä¸ªæ•°æ˜¯å¦åœ¨PyTorchå¼ é‡ä¸­,torch.any(tensor == number)
                    shutil.move(img_path,dst='/media/xnwu/2AC0DAF3C0DAC3EB/Datasets/DVR/data/20230614/20230614_for_obj_det_LA' )
            try:
                if torch.any(results[0].boxes.cls==3.) :  #  åˆ¤æ–­ä¸€ä¸ªæ•°æ˜¯å¦åœ¨PyTorchå¼ é‡ä¸­,torch.any(tensor == number)
                    shutil.move(img_path,dst='/media/xnwu/2AC0DAF3C0DAC3EB/Datasets/DVR/data/20230614/20230614_for_obj_det_RA' )
            except:
                pass
            
            try:
                if torch.any(results[0].boxes.cls==4.) :  #  åˆ¤æ–­ä¸€ä¸ªæ•°æ˜¯å¦åœ¨PyTorchå¼ é‡ä¸­,torch.any(tensor == number)
                    shutil.move(img_path,dst='/media/xnwu/2AC0DAF3C0DAC3EB/Datasets/DVR/data/20230614/20230614_for_obj_det_SLA' )
            except:
                pass
            
            try:
                if torch.any(results[0].boxes.cls==5.) :  #  åˆ¤æ–­ä¸€ä¸ªæ•°æ˜¯å¦åœ¨PyTorchå¼ é‡ä¸­,torch.any(tensor == number)
                    shutil.move(img_path,dst='/media/xnwu/2AC0DAF3C0DAC3EB/Datasets/DVR/data/20230614/20230614_for_obj_det_SRA' )
            except:
                pass
            # if len(results[0].boxes.cls)>0 and (results[0].boxes.cls == 1.).all().item():  #  ä½¿ç”¨(tensor == value).all()æ¥åˆ¤æ–­å¼ é‡ä¸­çš„æ‰€æœ‰å…ƒç´ æ˜¯å¦éƒ½ç­‰äºç»™å®šçš„å€¼
            #     shutil.move(img_path,dst='/media/xnwu/2AC0DAF3C0DAC3EB/Datasets/DVR/data/20230614/20230614_for_obj_det_onlyPC' )
           
            # if ( len(results[0].boxes.cls)>0 and (results[0].boxes.cls == 2.).all().item() ) or  \
            #             ( (torch.any(results[0].boxes.cls==1.) ) and (torch.any(results[0].boxes.cls==2.))and (results[0].boxes.shape[0] ==2) ):  #åˆ¤æ–­æ‰€æœ‰çš„å…ƒç´ éƒ½ä¸º2,æˆ–è€…åªæœ‰1å’Œ2,ä¸¤è€…æ··åˆå­˜åœ¨
            #     shutil.move(img_path,dst='/media/xnwu/2AC0DAF3C0DAC3EB/Datasets/DVR/data/20230614/20230614_for_obj_det_onlySA' )
            
            #ta
        return results
